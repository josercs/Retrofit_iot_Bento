[agent]
  interval = "5s"
  round_interval = true
  flush_interval = "5s"
  debug = true

# MQTT input
[[inputs.mqtt_consumer]]
  servers = ["ssl://mosquitto:8883"]
  topics = ["plc/#","plc/db1"]
  username = "edge_agent"                 # ajuste conforme seu mosquitto
  password = "NOVA_SENHA"
  qos = 1
  client_id = "telegraf-edge"
  persistent_session = true
  insecure_skip_verify = true
  data_format = "json_v2"
  [[inputs.mqtt_consumer.json_v2]]
    measurement_name = "s7_db500"
    [[inputs.mqtt_consumer.json_v2.object]]
      path = "values"
  # Ingest all numeric/boolean children of 'values' automatically
    [[inputs.mqtt_consumer.json_v2.tag]]
      path = "tenant_id"
      rename = "tenant_id"
    [[inputs.mqtt_consumer.json_v2.tag]]
      path = "plc_id"
      rename = "plc_id"

[[inputs.prometheus]]
  # Scrape the collector container directly inside the Compose network
  # Prefer container_name DNS (edge-collector) if service name isn't resolvable.
  urls = ["http://edge-collector:9108/metrics"]
  timeout = "10s"
  metric_version = 2

# InfluxDB v2 output
[[outputs.influxdb_v2]]
  urls = ["http://influxdb:8086"]
  token = "${INFLUX_TOKEN}"
  organization = "planta"
  bucket = "processo"
  timeout = "10s"
  content_encoding = "gzip"
  # Ajuste para reduzir overhead e evitar perdas por overflow
  metric_batch_size = 100
  metric_buffer_limit = 1000

[[outputs.influxdb_v2]]
  # Bucket bruto sem retenção para downsampling
  urls = ["http://influxdb:8086"]
  token = "$INFLUX_TOKEN"
  organization = "planta"
  bucket = "processo_raw"
  timeout = "10s"
  content_encoding = "gzip"
  metric_batch_size = 100
  metric_buffer_limit = 1000

[[processors.rename]]
  [[processors.rename.replace]]
    field = "plc_id"
    dest = "plc_id"
  # Se plc_id não vier, usar ip como fallback em outro processor (exemplo simplificado)

[[processors.converter]]
  [processors.converter.tags]
  string = ["plc_id", "tenant_id"]
  [processors.converter.fields]
    integer = []

# Derivação condicional a partir do tópico (só se a tag NÃO existir)
# 1) Preencher tenant_id a partir de plc/<tenant>/<plc> quando tenant_id estiver ausente
[[processors.regex]]
  namepass = ["s7_db1","s7_db500"]
  # Não processar este bloco se já existir tenant_id (qualquer valor)
  tagdrop = { tenant_id = ["*"] }
  [[processors.regex.tags]]
    key = "topic"
    pattern = "^plc/([^/]+)/([^/]+)"
    replacement = "${1}"
    result_key = "tenant_id"

# 2) Preencher plc_id a partir de plc/<tenant>/<plc> quando plc_id estiver ausente
[[processors.regex]]
  namepass = ["s7_db1","s7_db500"]
  # Não processar este bloco se já existir plc_id (qualquer valor)
  tagdrop = { plc_id = ["*"] }
  [[processors.regex.tags]]
    key = "topic"
    pattern = "^plc/([^/]+)/([^/]+)"
    replacement = "${2}"
    result_key = "plc_id"

# 3) Fallback final: se ainda não houver plc_id, definir para HOSTNAME (não sobrescreve existentes)
[[processors.override]]
  namepass = ["s7_db1","s7_db500"]
  # Pula este processor se já existir plc_id
  tagdrop = { plc_id = ["*"] }
  [processors.override.tags]
    plc_id = "${HOSTNAME}"  # fallback

[[outputs.file]]
  files = ["/tmp/telegraf_out.lp"]
  data_format = "influx"

# Debug: write raw JSON for MQTT consumer to inspect payloads arriving from broker
[[outputs.file]]
  files = ["/tmp/mqtt_raw.json"]
  data_format = "json"
